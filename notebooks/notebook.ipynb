{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7c3a162a-2e9a-459a-bc91-3a35008586b0",
    "_uuid": "355c54dccfd0e1dfd44e342f7ea8fa31353dce11"
   },
   "source": [
    "# Basic Seq2Seq\n",
    "This is a basic seq2seq implementation to show what can be done for conversational models.  The task we'll train it on is predicting company responses to consumers.\n",
    "\n",
    "This notebook shows how to prepare the data and construct the Keras model, but will not train quickly!  Instead, it demonstrates how the network progresses toward natural responses, and allows replying to arbitrary text, as shown below.  Unfortunately, getting to interesting results takes longer than an hour on Kaggle's non-GPU notebooks, so you'll need to download the notebook and run on your own machine to get to interesting results.\n",
    "\n",
    "This configuration tops out at a test loss of ~1.8, and provides nuanced responses to some of the more requests, like \"[the I problem](http://www.refinery29.com/2017/11/179790/ios-11-1-bug-keyboard-problem)\" for @AppleSupport, after around 6 hours of training on a CUDA 5.0 GPU.\n",
    "\n",
    "![seq2seq model architecture](https://i.imgur.com/JmuryKu.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-30T18:05:47.655702Z",
     "start_time": "2017-11-30T18:05:46.287359Z"
    },
    "_cell_guid": "39717eda-bc31-4143-a87f-bac4eea63678",
    "_uuid": "e30b174032d05dd0048b02ca268f3b31cf5b183e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library versions:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/xavier/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras:2.1.1\n",
      "pandas:0.21.0\n",
      "sklearn:0.19.1\n",
      "nltk:3.2.5\n",
      "numpy:1.13.3\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "import time\n",
    "\n",
    "print('Library versions:')\n",
    "\n",
    "import keras\n",
    "print(f'keras:{keras.__version__}')\n",
    "import pandas as pd\n",
    "print(f'pandas:{pd.__version__}')\n",
    "import sklearn\n",
    "print(f'sklearn:{sklearn.__version__}')\n",
    "import nltk\n",
    "print(f'nltk:{nltk.__version__}')\n",
    "import numpy as np\n",
    "print(f'numpy:{np.__version__}')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import casual_tokenize\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm # Special jupyter notebook progress bar ðŸ’«"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "24fb3871-ea0e-4b9e-b21c-ed76ccefc823",
    "_uuid": "ec0199c0dff22aeed45b9dbe1e7bf659e9449fe9"
   },
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-30T18:05:47.677113Z",
     "start_time": "2017-11-30T18:05:47.658247Z"
    },
    "_cell_guid": "3217b16f-bf7c-4fed-bbea-d74e09a537e4",
    "_uuid": "6509f5443163b0d11f1a003bb8a28b79a340f192"
   },
   "outputs": [],
   "source": [
    "# 8192 - large enough for demonstration, larger values make network training slower\n",
    "MAX_VOCAB_SIZE = 2**13\n",
    "# seq2seq generally relies on fixed length message vectors - longer messages provide more info\n",
    "# but result in slower training and larger networks\n",
    "MAX_MESSAGE_LEN = 30  \n",
    "# Embedding size for words - gives a trade off between expressivity of words and network size\n",
    "EMBEDDING_SIZE = 100\n",
    "# Embedding size for whole messages, same trade off as word embeddings\n",
    "CONTEXT_SIZE = 100\n",
    "# Larger batch sizes generally reach the average response faster, but small batch sizes are\n",
    "# required for the model to learn nuanced responses.  Also, GPU memory limits max batch size.\n",
    "BATCH_SIZE = 4\n",
    "# Helps regularize network and prevent overfitting.\n",
    "DROPOUT = 0.2\n",
    "# High learning rate helps model reach average response faster, but can make it hard to \n",
    "# converge on nuanced responses\n",
    "LEARNING_RATE=0.005\n",
    "\n",
    "# Tokens needed for seq2seq\n",
    "UNK = 0  # words that aren't found in the vocab\n",
    "PAD = 1  # after message has finished, this fills all remaining vector positions\n",
    "START = 2  # provided to the model at position 0 for every response predicted\n",
    "\n",
    "# Implementaiton detail for allowing this to be run in Kaggle's notebook hardware\n",
    "SUB_BATCH_SIZE = 1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ea67c840-2d02-45df-be0b-ec5746e72028",
    "_uuid": "9f99990233daf26e624d6e0a735b8a3559eb54c9"
   },
   "source": [
    "## Data Prep\n",
    "Here, we'll prepare the data for training our seq2seq model, including:\n",
    "\n",
    "- Replace screen names with `@__sn__` token to show model the commonality between them\n",
    "- Build a vocab to turn tokens into integers suitable for our seq2seq model\n",
    "- Tokenize input and target text into fixed size vectors\n",
    "- Partition our dataset into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7e83096b-f411-494a-962b-80a76122e674",
    "_uuid": "8989bdc2a930380aa52af0ef6a296906d313715c"
   },
   "source": [
    "### Data Loading and Reshaping\n",
    "Pulled from [this kernel](https://www.kaggle.com/soaxelbrooke/first-inbound-and-response-tweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-30T18:06:21.132168Z",
     "start_time": "2017-11-30T18:06:14.722472Z"
    },
    "_cell_guid": "c9f2bbcb-e843-42d9-81ec-70be9465c4a8",
    "_uuid": "0c3d1708c29764aceb980a93bd9ac61fdf852a22",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb537db1ac24494860536482e0d35bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 5.47 s, sys: 932 ms, total: 6.4 s\n",
      "Wall time: 6.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets = pd.read_pickle('../data/tweets.pkl')\n",
    "\n",
    "first_inbound = tweets[pd.isnull(tweets.in_response_to_tweet_id) & tweets.inbound]\n",
    "\n",
    "inbounds_and_outbounds = pd.merge(first_inbound, tweets, left_on='tweet_id', \n",
    "                                  right_on='in_response_to_tweet_id').sample(frac=1)\n",
    "\n",
    "# Filter to only outbound replies (from companies)\n",
    "inbounds_and_outbounds = inbounds_and_outbounds[inbounds_and_outbounds.inbound_y ^ True]\n",
    "\n",
    "tqdm().pandas()  # Enable tracking of progress in dataframe `apply` calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-30T18:06:21.137534Z",
     "start_time": "2017-11-30T18:06:21.133977Z"
    },
    "_cell_guid": "1510aa86-71ce-41b6-bda9-6bec1206836b",
    "_uuid": "67186b1ace1e3fff0fed9ec9fe6fd0c59f009a5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (630633, 20)\n"
     ]
    }
   ],
   "source": [
    "print(f'Data shape: {inbounds_and_outbounds.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a0afc1aa-a34f-4ea5-b34e-2fb21b5da62e",
    "_uuid": "2478590bbc0924cc8e8dd127ac4fea8019f8b3f3"
   },
   "source": [
    "### Tokenizing and Vocab Build\n",
    "\n",
    "We'll use NLTK's `casual_tokenize`, which handles a lot of corner cases found in social media data (\"casual\" text data) along with scitkit learn's `CountVectorizer`.  We won't use the actual `CountVectorizer`, just use it as a convenient vocabulary builder, which we'll apply with functions that turn text into \"word indexes\" - integers that represent each word - and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-30T18:06:21.171331Z",
     "start_time": "2017-11-30T18:06:21.139300Z"
    },
    "_cell_guid": "cab88942-373b-42fa-ac15-f341b19ced6f",
    "_uuid": "eccc4fdc8c0770ccb650c2fea30d7c4c5644ee4b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id_x</th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>inbound_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>response_tweet_id_x</th>\n",
       "      <th>in_response_to_tweet_id_x</th>\n",
       "      <th>date_x</th>\n",
       "      <th>month_x</th>\n",
       "      <th>day_x</th>\n",
       "      <th>time_x</th>\n",
       "      <th>tweet_id_y</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>inbound_y</th>\n",
       "      <th>text_y</th>\n",
       "      <th>response_tweet_id_y</th>\n",
       "      <th>in_response_to_tweet_id_y</th>\n",
       "      <th>date_y</th>\n",
       "      <th>month_y</th>\n",
       "      <th>day_y</th>\n",
       "      <th>time_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>639979</th>\n",
       "      <td>2181703</td>\n",
       "      <td>626067</td>\n",
       "      <td>True</td>\n",
       "      <td>We are still down here in oahu #tmobiledown @T...</td>\n",
       "      <td>2181702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-17 01:01:46</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>01:01:46</td>\n",
       "      <td>2181702</td>\n",
       "      <td>TMobileHelp</td>\n",
       "      <td>False</td>\n",
       "      <td>@626067 Hey Robby! I'm on Oahu and I can help!...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2181703.0</td>\n",
       "      <td>2017-11-17 01:35:33</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>01:35:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421427</th>\n",
       "      <td>1498164</td>\n",
       "      <td>449580</td>\n",
       "      <td>True</td>\n",
       "      <td>@95974 @AppleSupport very frustrated with iOS ...</td>\n",
       "      <td>1498163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-07 03:20:26</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>03:20:26</td>\n",
       "      <td>1498163</td>\n",
       "      <td>AppleSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>@449580 Thanks for contacting us! We're here t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1498164.0</td>\n",
       "      <td>2017-11-07 05:26:00</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>05:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271264</th>\n",
       "      <td>968193</td>\n",
       "      <td>328752</td>\n",
       "      <td>True</td>\n",
       "      <td>.@AmericanAir after 5gate changes it doesn't m...</td>\n",
       "      <td>968192,968194,968195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-10-26 16:13:48</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16:13:48</td>\n",
       "      <td>968192</td>\n",
       "      <td>AmericanAir</td>\n",
       "      <td>False</td>\n",
       "      <td>@328752 We do our best to avoid delays if we c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>968193.0</td>\n",
       "      <td>2017-10-26 16:15:08</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16:15:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407111</th>\n",
       "      <td>1449192</td>\n",
       "      <td>210972</td>\n",
       "      <td>True</td>\n",
       "      <td>Yet another spicy bread sauce from @sainsburys...</td>\n",
       "      <td>1449190,1449194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-05 12:17:22</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>12:17:22</td>\n",
       "      <td>1449190</td>\n",
       "      <td>sainsburys</td>\n",
       "      <td>False</td>\n",
       "      <td>@210972 ...add your refund to the same Nectar ...</td>\n",
       "      <td>1449191</td>\n",
       "      <td>1449192.0</td>\n",
       "      <td>2017-11-06 09:05:12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>09:05:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600483</th>\n",
       "      <td>2048724</td>\n",
       "      <td>595044</td>\n",
       "      <td>True</td>\n",
       "      <td>Dear Apple/ iPhone,\\n\\nCurrently, my phone is ...</td>\n",
       "      <td>2048723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-14 16:24:18</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>16:24:18</td>\n",
       "      <td>2048723</td>\n",
       "      <td>AppleSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>@595044 Hey Jerome, we'd like to look into the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2048724.0</td>\n",
       "      <td>2017-11-14 17:14:29</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>17:14:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id_x author_id_x  inbound_x  \\\n",
       "639979    2181703      626067       True   \n",
       "421427    1498164      449580       True   \n",
       "271264     968193      328752       True   \n",
       "407111    1449192      210972       True   \n",
       "600483    2048724      595044       True   \n",
       "\n",
       "                                                   text_x  \\\n",
       "639979  We are still down here in oahu #tmobiledown @T...   \n",
       "421427  @95974 @AppleSupport very frustrated with iOS ...   \n",
       "271264  .@AmericanAir after 5gate changes it doesn't m...   \n",
       "407111  Yet another spicy bread sauce from @sainsburys...   \n",
       "600483  Dear Apple/ iPhone,\\n\\nCurrently, my phone is ...   \n",
       "\n",
       "         response_tweet_id_x  in_response_to_tweet_id_x              date_x  \\\n",
       "639979               2181702                        NaN 2017-11-17 01:01:46   \n",
       "421427               1498163                        NaN 2017-11-07 03:20:26   \n",
       "271264  968192,968194,968195                        NaN 2017-10-26 16:13:48   \n",
       "407111       1449190,1449194                        NaN 2017-11-05 12:17:22   \n",
       "600483               2048723                        NaN 2017-11-14 16:24:18   \n",
       "\n",
       "        month_x  day_x    time_x tweet_id_y   author_id_y  inbound_y  \\\n",
       "639979       11      4  01:01:46    2181702   TMobileHelp      False   \n",
       "421427       11      1  03:20:26    1498163  AppleSupport      False   \n",
       "271264       10      3  16:13:48     968192   AmericanAir      False   \n",
       "407111       11      6  12:17:22    1449190    sainsburys      False   \n",
       "600483       11      1  16:24:18    2048723  AppleSupport      False   \n",
       "\n",
       "                                                   text_y response_tweet_id_y  \\\n",
       "639979  @626067 Hey Robby! I'm on Oahu and I can help!...                 NaN   \n",
       "421427  @449580 Thanks for contacting us! We're here t...                 NaN   \n",
       "271264  @328752 We do our best to avoid delays if we c...                 NaN   \n",
       "407111  @210972 ...add your refund to the same Nectar ...             1449191   \n",
       "600483  @595044 Hey Jerome, we'd like to look into the...                 NaN   \n",
       "\n",
       "        in_response_to_tweet_id_y              date_y  month_y  day_y  \\\n",
       "639979                  2181703.0 2017-11-17 01:35:33       11      4   \n",
       "421427                  1498164.0 2017-11-07 05:26:00       11      1   \n",
       "271264                   968193.0 2017-10-26 16:15:08       10      3   \n",
       "407111                  1449192.0 2017-11-06 09:05:12       11      0   \n",
       "600483                  2048724.0 2017-11-14 17:14:29       11      1   \n",
       "\n",
       "          time_y  \n",
       "639979  01:35:33  \n",
       "421427  05:26:00  \n",
       "271264  16:15:08  \n",
       "407111  09:05:12  \n",
       "600483  17:14:29  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbounds_and_outbounds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-30T18:06:33.359333Z",
     "start_time": "2017-11-30T18:06:21.173271Z"
    },
    "_cell_guid": "1efdae4f-8ff9-4242-be79-06916771da66",
    "_uuid": "44f124ae8898978cf5c1e571da976888f8229894"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing anonymized screen names in X...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e9d5f5d33f440d68d86f9b8e1e72ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630633), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing anonymized screen names in Y...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a85a2f72244172a3b4311d57f7c33e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630633), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace anonymized screen names with common token @__sn__\n",
    "def sn_replace(match):\n",
    "    _sn = match.group(2).lower()\n",
    "    if not _sn.isnumeric():\n",
    "        # This is a company screen name\n",
    "        return match.group(1) + match.group(2)\n",
    "    return '@__sn__'\n",
    "\n",
    "sn_re = re.compile('(\\W@|^@)([a-zA-Z0-9_]+)')\n",
    "print(\"Replacing anonymized screen names in X...\")\n",
    "x_text = inbounds_and_outbounds.text_x.progress_apply(lambda txt: sn_re.sub(sn_replace, txt))\n",
    "print(\"Replacing anonymized screen names in Y...\")\n",
    "y_text = inbounds_and_outbounds.text_y.progress_apply(lambda txt: sn_re.sub(sn_replace, txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-30T18:08:26.289246Z",
     "start_time": "2017-11-30T18:06:33.361276Z"
    },
    "_cell_guid": "eba2c6e6-f57e-438e-983f-d19c5156c817",
    "_uuid": "e3f3adeb6aebe8a90bdd7bfcd4fd6cff797d85ad",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CountVectorizer on X and Y text data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5a91591e8a4ea98d18b747e0c6383e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630633), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learned vocab of 8192 items.\n"
     ]
    }
   ],
   "source": [
    "count_vec = CountVectorizer(tokenizer=casual_tokenize, max_features=MAX_VOCAB_SIZE - 3)\n",
    "print(\"Fitting CountVectorizer on X and Y text data...\")\n",
    "count_vec.fit(tqdm(x_text + y_text))\n",
    "analyzer = count_vec.build_analyzer()\n",
    "vocab = {k: v + 3 for k, v in count_vec.vocabulary_.items()}\n",
    "vocab['__unk__'] = UNK\n",
    "vocab['__pad__'] = PAD\n",
    "vocab['__start__'] = START\n",
    "# Used to turn seq2seq predictions into human readable strings\n",
    "reverse_vocab = {v: k for k, v in vocab.items()}\n",
    "print(f\"Learned vocab of {len(vocab)} items.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c01e85bb-974d-4bf3-8eb1-b5893ce8f284",
    "_uuid": "893cae536132c7477699350574f5de0fd7a60a3f"
   },
   "source": [
    "### Vocab Helper Functions\n",
    "These helper functions take strings and turn them into word indexes used by the actual seq2seq models.  This turns something like \"This is how we do it.\" into a padded array of integers, like [153, 4, 643, 48, 94, 54, 8, 0, 0, 0].  We'll apply the `to_word_idx` function to our text data to get our `N x MESSAGE_LEN` training/test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-30T18:08:26.298665Z",
     "start_time": "2017-11-30T18:08:26.291854Z"
    },
    "_cell_guid": "d04887da-5ca9-4380-949e-7f7923a85df8",
    "_uuid": "b32c76052be9f5493b7eeee1cf40435e438eb3ca"
   },
   "outputs": [],
   "source": [
    "def to_word_idx(sentence):\n",
    "    full_length = [vocab.get(tok, UNK) for tok in analyzer(sentence)] + [PAD] * MAX_MESSAGE_LEN\n",
    "    return full_length[:MAX_MESSAGE_LEN]\n",
    "\n",
    "def from_word_idx(word_idxs):\n",
    "    return ' '.join(reverse_vocab[idx] for idx in word_idxs if idx != PAD).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-30T18:08:26.307745Z",
     "start_time": "2017-11-30T18:08:26.300625Z"
    },
    "_cell_guid": "f4b791c1-48a3-4cff-895f-a9140a93c831",
    "_uuid": "3ac8190e6d5985151dbfd5a11a502a389279bad7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "639979    we are still down here in __unk__ __unk__ @tmo...\n",
       "421427    @__sn__ @applesupport very frustrated with ios...\n",
       "271264    . @americanair after __unk__ changes it doesn'...\n",
       "407111    yet another spicy bread sauce from @sainsburys...\n",
       "600483    dear apple / iphone , currently , my phone is ...\n",
       "Name: text_x, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure our helpers work as expected...\n",
    "x_text.head().apply(to_word_idx).apply(from_word_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-30T18:10:24.542505Z",
     "start_time": "2017-11-30T18:08:26.309673Z"
    },
    "_cell_guid": "d1977e30-2cc7-4786-91b2-10dbaa63f17d",
    "_uuid": "74951a1b74353c31e5e64a68d0f329f1efa9543d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating word indexes for X...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d02ba003be5483d906852fba1c5c89f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630633), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating word indexes for Y...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1afe2f29ce486ea06786b08327b9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630633), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating word indexes for X...\")\n",
    "x = pd.np.vstack(x_text.progress_apply(to_word_idx).values)\n",
    "print(\"Calculating word indexes for Y...\")\n",
    "y = pd.np.vstack(y_text.progress_apply(to_word_idx).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "edebf7ab-0495-4e38-9900-7a9652cdb2d0",
    "_uuid": "f9f842020ecb321805c9032d20b01f1ffe6f5885"
   },
   "source": [
    "### Train / Test Split\n",
    "Here, we split our data into training and test sets.  For simplicity, we use a random split, which may result in different distributions between the training and test set, but we won't worry about that for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-30T18:10:25.881762Z",
     "start_time": "2017-11-30T18:10:24.547111Z"
    },
    "_cell_guid": "67b9f6e4-2619-48c9-9339-da6637e646d3",
    "_uuid": "d4f3b7134ac395a1952f8dc816cedad201cdf0a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data of shape (504506, 30) and test data of shape (126127, 30).\n"
     ]
    }
   ],
   "source": [
    "all_idx = list(range(len(x)))\n",
    "train_idx = set(random.sample(all_idx, int(0.8 * len(all_idx))))\n",
    "test_idx = {idx for idx in all_idx if idx not in train_idx}\n",
    "\n",
    "train_x = x[list(train_idx)]\n",
    "test_x = x[list(test_idx)]\n",
    "train_y = y[list(train_idx)]\n",
    "test_y = y[list(test_idx)]\n",
    "\n",
    "assert train_x.shape == train_y.shape\n",
    "assert test_x.shape == test_y.shape\n",
    "\n",
    "print(f'Training data of shape {train_x.shape} and test data of shape {test_x.shape}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9764b6aa-13e3-409e-939e-64f7f7083350",
    "_uuid": "89c827fa1a1aabc990e6b04b4a4839bd04b9b42c"
   },
   "source": [
    "## Model Creation\n",
    "We'll create and compile the model here.  It will consist of the following components:\n",
    "\n",
    "- Shared word embeddings\n",
    "  - A shared embedding layer that turns word indexes (a sparse representation) into a dense/compressed representation.  This embeds both the request from the customer, and also the last words uttered by the model that are fed back into the model.\n",
    "- Encoder RNN\n",
    "  - In this case, a single LSTM layer.  This encodes the whole input sentence into a context vector (or thought vector) that represents completely what the customer is saying, and produces a single output.\n",
    "- Decoder RNN\n",
    "  - This RNN (also an LSTM in this case) decodes the context vector into a string of tokens/utterances.  For each time step, it takes the context vector and the embedded last utterance and produces the next utterance, which is fed back into the model.  More complex and effective models copy the encoder state into the decoder, add more layers of LSTMs, and apply attention mechanisms - but these are out of the scope of this simple example.\n",
    "- Next Word Dense+Softmax\n",
    "  - These two layers take the decoder output and turn it into the next word to be uttered.  The dense layer allows the decoder to not map directly to words uttered, and the softmax turns the dense layer output into a probability distribution, from which we pick the most likely next word.\n",
    "\n",
    "![seq2seq model structure](https://i.imgur.com/JmuryKu.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-30T18:06:18.185Z"
    },
    "_cell_guid": "ee656365-3b04-4dfc-a4dc-a4081ceea82d",
    "_uuid": "46bea6af349b1b67b870eb5977c2bd0c798e2b86"
   },
   "outputs": [],
   "source": [
    "# keras imports, because there are like... A million of them.\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Input, LSTM, Dropout, Embedding, RepeatVector, concatenate, \\\n",
    "    TimeDistributed\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-30T18:06:18.370Z"
    },
    "_cell_guid": "d0a87457-573a-43b8-9a0a-d869a75b86ba",
    "_uuid": "420e809e7f3c9986bf4d3e3804198b8205e4a772",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    shared_embedding = Embedding(\n",
    "        output_dim=EMBEDDING_SIZE,\n",
    "        input_dim=MAX_VOCAB_SIZE,\n",
    "        input_length=MAX_MESSAGE_LEN,\n",
    "        name='embedding',\n",
    "    )\n",
    "    \n",
    "    # ENCODER\n",
    "    \n",
    "    encoder_input = Input(\n",
    "        shape=(MAX_MESSAGE_LEN,),\n",
    "        dtype='int32',\n",
    "        name='encoder_input',\n",
    "    )\n",
    "    \n",
    "    embedded_input = shared_embedding(encoder_input)\n",
    "    \n",
    "    # No return_sequences - since the encoder here only produces a single value for the\n",
    "    # input sequence provided.\n",
    "    encoder_rnn = LSTM(\n",
    "        CONTEXT_SIZE,\n",
    "        name='encoder',\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "    \n",
    "    context = RepeatVector(MAX_MESSAGE_LEN)(encoder_rnn(embedded_input))\n",
    "    \n",
    "    # DECODER\n",
    "    \n",
    "    last_word_input = Input(\n",
    "        shape=(MAX_MESSAGE_LEN, ),\n",
    "        dtype='int32',\n",
    "        name='last_word_input',\n",
    "    )\n",
    "    \n",
    "    embedded_last_word = shared_embedding(last_word_input)\n",
    "    # Combines the context produced by the encoder and the last word uttered as inputs\n",
    "    # to the decoder.\n",
    "    decoder_input = concatenate([embedded_last_word, context], axis=2)\n",
    "    \n",
    "    # return_sequences causes LSTM to produce one output per timestep instead of one at the\n",
    "    # end of the intput, which is important for sequence producing models.\n",
    "    decoder_rnn = LSTM(\n",
    "        CONTEXT_SIZE,\n",
    "        name='decoder',\n",
    "        return_sequences=True,\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "    \n",
    "    decoder_output = decoder_rnn(decoder_input)\n",
    "    \n",
    "    # TimeDistributed allows the dense layer to be applied to each decoder output per timestep\n",
    "    next_word_dense = TimeDistributed(\n",
    "        Dense(int(MAX_VOCAB_SIZE / 2), activation='relu'),\n",
    "        name='next_word_dense',\n",
    "    )(decoder_output)\n",
    "    \n",
    "    next_word = TimeDistributed(\n",
    "        Dense(MAX_VOCAB_SIZE, activation='softmax'),\n",
    "        name='next_word_softmax'\n",
    "    )(next_word_dense)\n",
    "    \n",
    "    return Model(inputs=[encoder_input, last_word_input], outputs=[next_word])\n",
    "\n",
    "s2s_model = create_model()\n",
    "optimizer = Adam(lr=LEARNING_RATE, clipvalue=5.0)\n",
    "s2s_model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "37dc7acc-ed74-4933-9182-b4329258d31f",
    "_uuid": "261fdad98295fa395592a5a6bf60806151a51c74"
   },
   "source": [
    "## Model Training\n",
    "We'll train the model here.  After each sub-batch of the dataset, we'll test with static input strings to see how the model is progressing in human readable terms.  Its important to have these tests along with traditional model evaluation to provide a better understanding of how well the model is training.\n",
    "\n",
    "It's important to pull test strings from the real distribution of the data, also.  It can be hard to really put yourself in customers' shoes when writing test messages, and you will get non-representative results when you provide test examples that don't fit the true distribution of the input data (when your input text doesn't sound like real customer requests)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-30T18:06:18.766Z"
    },
    "_cell_guid": "db2eee93-8070-4572-962e-c7225b20d2e4",
    "_uuid": "464355ec34af2c192723e66222c036826ac323f7"
   },
   "outputs": [],
   "source": [
    "def add_start_token(y_array):\n",
    "    \"\"\" Adds the start token to vectors.  Used for training data. \"\"\"\n",
    "    return np.hstack([\n",
    "        START * np.ones((len(y_array), 1)),\n",
    "        y_array[:, :-1],\n",
    "    ])\n",
    "\n",
    "def binarize_labels(labels):\n",
    "    \"\"\" Helper function that turns integer word indexes into sparse binary matrices for \n",
    "        the expected model output.\n",
    "    \"\"\"\n",
    "    return np.array([np_utils.to_categorical(row, num_classes=MAX_VOCAB_SIZE)\n",
    "                     for row in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-30T18:06:18.957Z"
    },
    "_cell_guid": "ce33ef3c-90df-4d3f-aad7-82db7b8cbf38",
    "_uuid": "982ca948fcf372ba6d29cc1872b9667c8e7c678f"
   },
   "outputs": [],
   "source": [
    "def respond_to(model, text):\n",
    "    \"\"\" Helper function that takes a text input and provides a text output. \"\"\"\n",
    "    input_y = add_start_token(PAD * np.ones((1, MAX_MESSAGE_LEN)))\n",
    "    idxs = np.array(to_word_idx(text)).reshape((1, MAX_MESSAGE_LEN))\n",
    "    for position in range(MAX_MESSAGE_LEN - 1):\n",
    "        prediction = model.predict([idxs, input_y]).argmax(axis=2)[0]\n",
    "        input_y[:,position + 1] = prediction[position]\n",
    "    return from_word_idx(model.predict([idxs, input_y]).argmax(axis=2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-30T18:06:19.138Z"
    },
    "_cell_guid": "3fb77b82-c4c3-4328-89a9-4c679744018c",
    "_uuid": "134fb65418234dd849a6d0147f95728373ea80a0"
   },
   "outputs": [],
   "source": [
    "def train_mini_epoch(model, start_idx, end_idx):\n",
    "    \"\"\" Batching seems necessary in Kaggle Jupyter Notebook environments, since\n",
    "        `model.fit` seems to freeze on larger batches (somewhere 1k-10k).\n",
    "    \"\"\"\n",
    "    b_train_y = binarize_labels(train_y[start_idx:end_idx])\n",
    "    input_train_y = add_start_token(train_y[start_idx:end_idx])\n",
    "    \n",
    "    model.fit(\n",
    "        [train_x[start_idx:end_idx], input_train_y], \n",
    "        b_train_y,\n",
    "        epochs=1,\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )\n",
    "    \n",
    "    rand_idx = random.sample(list(range(len(test_x))), SUB_BATCH_SIZE)\n",
    "    print('Test results:', model.evaluate(\n",
    "        [test_x[rand_idx], add_start_token(test_y[rand_idx])],\n",
    "        binarize_labels(test_y[rand_idx])\n",
    "    ))\n",
    "    \n",
    "    input_strings = [\n",
    "        \"@AppleSupport I fix I this I stupid I problem I\",\n",
    "        \"@AmazonHelp I hadnt expected that such a big brand like amazon would have such a poor customer service.\",\n",
    "    ]\n",
    "    \n",
    "    for input_string in input_strings:\n",
    "        output_string = respond_to(model, input_string)\n",
    "        print(f'> \"{input_string}\"\\n< \"{output_string}\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8a481fec-429a-45c5-bbb7-5f8f7e0e2487",
    "_uuid": "00e0850fe55d06f6d86c71c055ee45d8a0086c21"
   },
   "source": [
    "### Train the model!\n",
    "\n",
    "You can stop training by pressing the stop button - the training code is configured to watch for the `KeyboardInterrupt` exception triggered that way.  Also, it will run until the configured stopping point below.\n",
    "\n",
    "\n",
    "Let's start the training! ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-30T18:06:19.521Z"
    },
    "_cell_guid": "450d8fd0-25b2-41cb-ad3b-dbb266568b72",
    "_uuid": "790bb2978f320f7988f0e850026f264a434b5c3e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_time_limit = 360 * 60  # seconds (notebooks terminate after 1 hour)\n",
    "start_time = time.time()\n",
    "stop_after = start_time + training_time_limit\n",
    "\n",
    "class TimesUpInterrupt(Exception):\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    for epoch in range(100):\n",
    "        print(f'Training in epoch {epoch}...')\n",
    "        for start_idx in range(0, len(train_x), SUB_BATCH_SIZE):\n",
    "            train_mini_epoch(s2s_model, start_idx, start_idx + SUB_BATCH_SIZE)\n",
    "            if time.time() > stop_after:\n",
    "                raise TimesUpInterrupt\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Halting training from keyboard interrupt.\")\n",
    "except TimesUpInterrupt:\n",
    "    print(f\"Halting after {time.time() - start_time} seconds spent training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-30T18:06:19.714Z"
    },
    "_cell_guid": "18a421a1-41d7-4c87-988d-74fa8dc85992",
    "_uuid": "8ebd6c01cd3a7e75810f9fc48b4d2ad913f9f410"
   },
   "outputs": [],
   "source": [
    "respond_to(s2s_model, '''@AppleSupport iPhone 8 touchID doesnt unlock while charging on \n",
    "    110v w/ 61w laptop charger to usbc lightning cable just uh.. so you guys know''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-30T18:06:20.573Z"
    },
    "_cell_guid": "eef56338-516e-46ed-94d5-6c7d21279d34",
    "_uuid": "e5f0a5acf6611334291cea8c3440c5dd3badf2f0"
   },
   "outputs": [],
   "source": [
    "respond_to(s2s_model, '''@sprintcare I can't make calls... wtf''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1445794c-c26f-4dc9-a38e-90b98ee206cb",
    "_uuid": "f7e4303f8ee7d2def95c95b166b6fac8727217f5",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
